---
title: "Regression analysis Case-Study"
author: "Martin Hanewald"
date: "1 August 2018"
output: 
    html_document:
        toc: true
        toc_float: true
        number_sections: true
        theme: lumen
        highlight: pygments
        df_print: paged
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
options(width = 110)
```


# Abstract

This analysis tries to predict the hourly demand of a bikeshare provider in Washington D.C. The dataset has been obtained from https://www.kaggle.com/c/bike-sharing-demand.

From kaggle description:

> Bike sharing systems are a means of renting bicycles where the process of obtaining membership, rental, and bike return is automated via a network of kiosk locations throughout a city. Using these systems, people are able rent a bike from a one location and return it to a different place on an as-needed basis. Currently, there are over 500 bike-sharing programs around the world.
The data generated by these systems makes them attractive for researchers because the duration of travel, departure location, arrival location, and time elapsed is explicitly recorded. Bike sharing systems therefore function as a sensor network, which can be used for studying mobility in a city. In this competition, participants are asked to combine historical usage patterns with weather data in order to forecast bike rental demand in the Capital Bikeshare program in Washington, D.C.

We first conduct an exploratory analysis towards the relationships between the predictor variables and the count variable.

Then we try out different models to evaluate the best fit.


# Configuration and libraries

```{r libraries, message=FALSE, warning=FALSE}
library(tidyverse)
library(caret)
library(lubridate)
```

```{r config, include = FALSE}
set.seed(1337)

# activate parallel processing
library(doParallel)
cl <- makePSOCKcluster(2)
registerDoParallel(cl)

# color Palette
qpal <- c("#009fe3","#023e84", "#2bad70", "#e8423b", "#1d1d1b", "#7c7c7b", "#d0d0d0", "#ffffff" )
```

# Loading data

```{r}
rawdat <- read_csv('data/bikeshare_train.csv')
rawdat
```

The data consists of 10.886 rows of hourly data. The variable count describes the number of bicycles rented. Aggregated on a daily basis we get the following timeseries.

```{r}
rawdat %>% mutate(day = date(datetime)) %>% 
    group_by(day) %>% 
    summarise(count = sum(count)) %>% 
    ggplot(aes(x=row_number(day), y = count)) + geom_area(fill = qpal[2]) +
    labs(x = "Day", y = 'Count', title='Rented bicycles per day')
```

# Preprocessing

## Feature Engineering

Some engineered  features like season, holiday and workingday have already been included in the dataset. But we want to add variables for **year, month and hour**.

Secondly the variable **count** is a typical Poisson distributed variable. In order to also work with models, which are not Poisson-compatible we add a log-transformed variable as well.

Furthermore all categorical variables need to be transformed to R's **factor** variable format.

```{r}
dat <- rawdat %>% 
    mutate(year = year(datetime),
           month = month(datetime),
           hour = hour(datetime)) %>% 
    mutate(logcount = log(count + 1)) %>% 
    mutate_at(vars(season, holiday, workingday, 
                   weather, year, month, hour), as.factor)

dat
```

```{r}
str(dat)
```


```{r message=FALSE}
dat %>% 
    ggplot(aes(x = count)) + geom_histogram(color=qpal[1], fill=qpal[2]) + labs(title='Histogram of count variable')

dat %>% 
    ggplot(aes(x = log(count+1))) + geom_histogram(color=qpal[1], fill=qpal[2]) + labs(title='Histogram of logcount variable')
```

```{r}
dat %>% ggplot(aes(x=hour, y=count, fill=hour)) + geom_boxplot()+
    labs(title='Distribution of count variable over hours')
```

```{r}
dat %>% ggplot(aes(x=month, y=count, fill=season)) + geom_boxplot() +
    labs(title='Distribution of count variable over months')
```

## Exploratory analysis

In general we have the strong assumption, that the weather influences the count variable. We check this assumption with scatterplots.

```{r}
dat %>% 
    ggplot(aes(x = temp, y = logcount)) +
    geom_jitter(alpha = .2, color=qpal[2], size = 2) + 
    geom_smooth(method='lm') +
    labs(title='Relation between temp and logcount')
```

Although we see a positive relationship between **logcount** and **temp** we see a weird pattern in the lower range, where the relation seems to break.

This is due to our failure to account for day and nighttime. Naturally the bike rentals during 3 am in the morning will not go up, even when it is warmer than usual.

Therefore we apply a filter to only look at hours from 8am to 20pm.

```{r}
dat %>% filter(as.numeric(hour) > 8, as.numeric(hour) < 20) %>% 
    ggplot(aes(x = temp, y = logcount)) +
    geom_jitter(alpha = .2, color=qpal[2], size = 2) + 
    geom_smooth(method='lm') +
    labs(title='Relation between temp and logcount (with daytime filter)')
```

```{r}
dat %>% filter(as.numeric(hour) > 8, as.numeric(hour) < 20) %>% 
    ggplot(aes(x = windspeed, y = logcount)) +
    geom_jitter(alpha = .2, color=qpal[2], size = 2) +
    geom_smooth(method='lm') +
    labs(title='Relation between windspeed and logcount (with daytime filter)')
```

```{r}
dat %>% filter(as.numeric(hour) > 8, as.numeric(hour) < 20) %>% 
    ggplot(aes(x = humidity, y = logcount)) +
    geom_jitter(alpha = .2, color=qpal[2], size = 2) +
    geom_smooth(method='lm') +
    labs(title='Relation between humidity and logcount (with daytime filter)')
```



```{r}
dat %>% 
    ggplot(aes(fill = holiday, y = logcount, x = holiday)) + geom_boxplot() +
    labs(title = 'Relation between holiday and logcount')
```

```{r}
dat %>% 
    ggplot(aes(fill = workingday, y = logcount, x = workingday)) + geom_boxplot() +
    labs(title = 'Relation between workingday and logcount')
```

## Splitting

We split our dataset with the 80/20 rule into training and testset by random sampling. This is done stratisfied on the **hour** variable, to retain an evenly distributed number of datasets per hour in both sets.

```{r}
modeldat <- dat %>%
    select(count, logcount, year, month, hour, season:windspeed)

intrain <- createDataPartition(modeldat$hour, p = .8, list =F)

training <- modeldat[intrain,]
testing <- modeldat[-intrain,]

training
```


```{r}
trainplot <- modeldat %>% mutate(Set = 'Testing')
trainplot$Set[intrain] <- 'Training'
trainplot %>% ggplot(aes(x=hour, fill=Set)) + geom_bar(stat='count') + labs(y='Datasets', title = 'Stratisfied split in training and testset on variable hour')
```

# Model Training

We activate 10-fold Cross-Validation for the training procedures.

```{r}
trControl <- trainControl(method = 'cv')
fit <- list()
```


## Linear regression

```{r warning=FALSE}
fit$lm <- train(logcount ~ . -count, 
                     data = training, 
                     method = 'lm',
                     trControl = trControl)

fit$lm
```

## Regression tree

```{r warning=FALSE}
fit$rpart <- train(logcount ~ . -count, 
                     data = training, 
                     method = 'rpart',
                     trControl = trControl,
                     tuneLength=10)

fit$rpart
```

## Bagged trees

```{r}
fit$treebag <- train(logcount ~ . -count,
                     data = training,
                     method = 'treebag',
                     trControl = trControl)

fit$treebag
```

## Boosted trees

```{r}

tuneGrid <- data.frame(nrounds = 150,
                       max_depth = 3,
                       eta = 0.4,
                       gamma = 0,
                       colsample_bytree= 0.8,
                       min_child_weight = 1,
                       subsample = 0.75)

fit$xgbtree <- train(logcount ~ . -count,
                     data = training,
                     method = 'xgbTree',
                     trControl = trControl
                     ,tuneGrid = tuneGrid
                     )

fit$xgbtree
```

# Model Evaluation

## Performance on training set
```{r}
rs <- resamples(fit)
bwplot(rs)
```

## Performance on test set

We apply the prediction of all models on the test set and compare performance
measures. It is important to note, that in order to avoid
overfitting on the test set, a selection for the "best" model should
already have been made on the basis of the cross-validated training results.

Applying all models on the test set is only shown for demonstrative purposes here and is
definitely not best practive.

```{r warning=FALSE}

prediction <- lapply(fit, predict, newdata = testing) %>% 
    bind_cols()

prediction %>% 
    sapply(postResample, obs = testing$logcount) %>% 
    as.data.frame() %>% 
    rownames_to_column('metric') %>% 
    gather(model, value, -metric) %>% 
    ggplot(aes(x=metric, y = value, fill = model)) + 
    geom_col(position='dodge') 

```

```{r, echo = F}
prediction %>% 
    sapply(postResample, obs = testing$logcount)
```

Also on the test set the boosted trees are performing best.

```{r warning=FALSE}
# Model fit on training
plotdat <- prediction %>%
    mutate_all(function(x) exp(x) - 1) %>% 
    bind_cols(testing %>% select(count)) %>% 
    arrange(desc(count)) %>% 
    rowid_to_column() %>%
    gather(type, value, -rowid)

```

```{r}
plotdat %>% filter(type %in% c('count', 'rpart')) %>% 
    ggplot(aes(x=rowid, y=value, color=type)) + geom_point(alpha =.5)
```

```{r}
plotdat %>% filter(type %in% c('count', 'treebag')) %>% 
    ggplot(aes(x=rowid, y=value, color=type)) + geom_point(alpha =.5)
```

```{r}
plotdat %>% filter(type %in% c('count', 'lm')) %>% 
    ggplot(aes(x=rowid, y=value, color=type)) + geom_point(alpha =.5)
```

```{r}
plotdat %>% filter(type %in% c('count', 'xgbtree')) %>% 
    ggplot(aes(x=rowid, y=value, color=type)) + geom_point(alpha =.5)
```

## Variable importance

We can extract and plot the relative importance each model attributes to
all the available variables.

The differences are quite striking.

```{r message=FALSE}
vi <- lapply(fit, function(x) 
    varImp(x)$importance %>% 
        rownames_to_column('var') %>% 
        set_names(c('var', x$method))
    )

vi$lm %>% full_join(vi$xgbtree) %>% full_join(vi$treebag) %>% 
    gather(model, importance, -var) %>% arrange(var) %>% 
    ggplot(aes(x=var, y = importance, fill=model)) + geom_col(position='dodge') +
    theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
    coord_flip()
```


```{r, eval = F}
varImp(fit$lm)
varImp(fit$rpart)
varImp(fit$treebag)
varImp(fit$xgbtree)
```


<!-- ## Outlier removal -->

<!-- Checking the distribution of the count variable on a per hour basis, we can see, that there are quite a few outliers. -->

<!-- ```{r} -->
<!-- dat_no_outliers %>% ggplot(aes(x=hour, y=logcount, fill=hour)) + geom_boxplot() -->
<!-- ``` -->


<!-- For outlier removal of the count variable we create a lookup table, which calculates the max threshold defined as **three standard deviations above the mean count.** This is done on an hour basis. -->

<!-- ```{r message=FALSE} -->
<!-- outlier_lookup <- dat %>%  -->
<!--     group_by(hour) %>%  -->
<!--     summarise(count_mean = mean(count),  -->
<!--               count_sd = sd(count), -->
<!--               count_max = count_mean + 3 * count_sd) -->
<!-- outlier_lookup -->
<!-- ``` -->

<!-- Then the lookup table is joined to the data and the filter is applied. -->

<!-- ```{r} -->
<!-- dat_no_outliers <- dat %>%  -->
<!--     inner_join(outlier_lookup) %>%  -->
<!--     filter(count < count_max) -->
<!-- ``` -->


<!-- ## Poisson regression on count -->

<!-- ```{r warning=FALSE} -->
<!-- fit$poisson <- train(count ~ . -logcount,  -->
<!--                      data = training,  -->
<!--                      method = 'glm', -->
<!--                      family = 'poisson', -->
<!--                      trControl = trControl) -->

<!-- fit$poisson -->
<!-- ``` -->

